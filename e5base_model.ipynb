{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Author: Alexis Geslin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3560,
     "status": "ok",
     "timestamp": 1741737075571,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 420
    },
    "id": "uTikNgInxK28"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "from statistics import stdev\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21150,
     "status": "ok",
     "timestamp": 1741737096724,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 420
    },
    "id": "JoUFIvSxxRAn",
    "outputId": "67982582-abdd-4ed4-e28a-49d7098ecca8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1218,
     "status": "ok",
     "timestamp": 1741737097942,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 420
    },
    "id": "kxjSCeMxxqGc",
    "outputId": "e1459cbd-f7c4-4b31-dddd-86be8c141eac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/cours/cs224n/project/LLM-Prop\n"
     ]
    }
   ],
   "source": [
    "%cd drive/MyDrive/cours/cs224n/project/LLM-Prop/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 759,
     "status": "ok",
     "timestamp": 1741737098728,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 420
    },
    "id": "WPW9SCD0xxh3",
    "outputId": "e0c42a80-a166-4550-ea13-896b86441611"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "I have 1 devices, currently on 0\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('-'*20)\n",
    "    print(f'I have {torch.cuda.device_count()} devices, currently on {torch.cuda.current_device()}')\n",
    "    print('-'*20)\n",
    "else:\n",
    "    print('-'*20)\n",
    "    print(\"You are running on CPU only\")\n",
    "    print('-'*20)\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 28468,
     "status": "ok",
     "timestamp": 1741737127199,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 420
    },
    "id": "Fgue-5Hxx0vZ"
   },
   "outputs": [],
   "source": [
    "train_labels_data = pd.read_csv(f'./embeddings/pred_labels_train_train15000_200epoch_125098.csv')\n",
    "valid_labels_data = pd.read_csv(f'./embeddings/pred_labels_valid_train15000_200epoch_9945.csv')\n",
    "test_labels_data = pd.read_csv(f'./embeddings/pred_labels_test_train15000_200epoch_11531.csv')\n",
    "\n",
    "train_embeddings  = pd.read_csv(f'./embeddings/e5base_train_125098.csv', header=None)\n",
    "valid_embeddings  = pd.read_csv(f'./embeddings/e5base_valid_9945.csv', header=None)\n",
    "test_embeddings  = pd.read_csv(f'./embeddings/e5base_test_11531.csv', header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 626,
     "status": "ok",
     "timestamp": 1741737212547,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 420
    },
    "id": "tCUP6xFoBgiM",
    "outputId": "68149734-be9d-4384-f979-e32048ac9365"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([125098, 768]) torch.Size([125098, 1]) cuda:0 cuda:0\n",
      "torch.Size([9945, 768]) torch.Size([9945, 1]) cuda:0 cuda:0\n",
      "torch.Size([11531, 768]) torch.Size([11531, 1]) cuda:0 cuda:0\n"
     ]
    }
   ],
   "source": [
    "#concat embeddings and numerical tokens and make it a tensor\n",
    "X_train = torch.tensor(train_embeddings.values).float().to(device)\n",
    "X_valid = torch.tensor(valid_embeddings.values).float().to(device)\n",
    "X_test = torch.tensor(test_embeddings.values).float().to(device)\n",
    "\n",
    "\n",
    "Y_train = torch.tensor(train_labels_data.label.values).float().reshape(-1,1).to(device)\n",
    "Y_valid = torch.tensor(valid_labels_data.label.values).float().reshape(-1,1).to(device)\n",
    "Y_test = torch.tensor(test_labels_data.label.values).float().reshape(-1,1).to(device)\n",
    "\n",
    "#print shapes\n",
    "print(X_train.shape, Y_train.shape,X_train.device,Y_train.device)\n",
    "print(X_valid.shape, Y_valid.shape,X_valid.device,Y_valid.device)\n",
    "print(X_test.shape, Y_test.shape,X_test.device,Y_test.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1741737212590,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 420
    },
    "id": "metr3R6-ytNG"
   },
   "outputs": [],
   "source": [
    "dim_embeddings = train_embeddings.shape[1]\n",
    "mae_loss_function = nn.L1Loss()\n",
    "mseloss = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1741737212920,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 420
    },
    "id": "9x2LCJBiytKy",
    "outputId": "ba53937b-5014-443b-b7e3-880cfe58d4b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    }
   ],
   "source": [
    "X_train_mini = X_train[:15000]\n",
    "Y_train_mini = Y_train[:15000]\n",
    "bs = 256 if torch.cuda.is_available() else 32\n",
    "print(bs)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "train_dataset_mini = torch.utils.data.TensorDataset(X_train_mini, Y_train_mini)\n",
    "valid_dataset = torch.utils.data.TensorDataset(X_valid, Y_valid)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, Y_test)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=bs, shuffle=False)\n",
    "train_dataloader_mini = torch.utils.data.DataLoader(train_dataset_mini, batch_size=bs, shuffle=False)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=bs, shuffle=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1741737215602,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 420
    },
    "id": "N0g_HPzpBqn1"
   },
   "outputs": [],
   "source": [
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(in_features, in_features)\n",
    "        self.bn = nn.BatchNorm1d(in_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return nn.functional.relu(self.bn(self.fc(x)) + x)\n",
    "\n",
    "class perceptronHead(nn.Module):\n",
    "    def __init__(self, embeddings_dim,mydroprate = 0.1):\n",
    "        super(perceptronHead, self).__init__()\n",
    "\n",
    "        self.MLP_embedding = nn.Sequential(\n",
    "            nn.Dropout(mydroprate),\n",
    "            nn.Linear(embeddings_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            ResidualBlock(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            ResidualBlock(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 1)\n",
    "        )\n",
    "        # initialize weights with Kaiming\n",
    "        for m in self.MLP_embedding:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                print(f'initialized {m}')\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        x_out = self.MLP_embedding(X)\n",
    "        return x_out\n",
    "\n",
    "class perceptronHead2(nn.Module):\n",
    "    def __init__(self, embeddings_dim,mydroprate = 0.1):\n",
    "        super(perceptronHead2, self).__init__()\n",
    "\n",
    "        self.MLP_embedding = nn.Sequential(\n",
    "            nn.Dropout(mydroprate),\n",
    "            ResidualBlock(embeddings_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embeddings_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            ResidualBlock(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 1)\n",
    "        )\n",
    "        # initialize weights with Kaiming\n",
    "        for m in self.MLP_embedding:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                print(f'initialized {m}')\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        x_out = self.MLP_embedding(X)\n",
    "        return x_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1741720112468,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 420
    },
    "id": "f3cF7atQB6MT",
    "outputId": "076a2732-0a7f-4093-fe93-f1c85d0b8ee3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized Linear(in_features=768, out_features=512, bias=True)\n",
      "initialized Linear(in_features=512, out_features=128, bias=True)\n",
      "initialized Linear(in_features=128, out_features=8, bias=True)\n",
      "initialized Linear(in_features=8, out_features=1, bias=True)\n"
     ]
    }
   ],
   "source": [
    "model = perceptronHead2(dim_embeddings,mydroprate=0.15)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0015)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "my_training_loader = train_dataloader_mini\n",
    "my_training_loader = train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 62,
     "status": "error",
     "timestamp": 1741732857262,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 420
    },
    "id": "oFLp4f7MCCOc",
    "outputId": "4982ce92-b1b1-411d-d42c-ee3ea8ed5fa3"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6996ec3128f7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbest_valid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000000000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_training_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "epochs =100\n",
    "\n",
    "best_valid_loss = 1000000000\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for i, (x, y) in enumerate(my_training_loader):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = mae_loss_function(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "        before_update = {name: param.clone().detach() for name, param in model.named_parameters()}\n",
    "        loss.backward()\n",
    "        # for name, param in model.named_parameters():\n",
    "        #     if param.grad is not None and torch.all(param.grad == 0):\n",
    "        #         print(f\"All-zero gradient for {name}\")\n",
    "        optimizer.step()\n",
    "\n",
    "        # for name, param in model.named_parameters():\n",
    "        #     if torch.equal(before_update[name], param):\n",
    "        #         print(f\"No update for {name}\")\n",
    "        # if i % 10000 == 0:\n",
    "    train_loss /= len(my_training_loader)\n",
    "    print(f'Epoch {epoch}, Training Loss {round((train_loss),3)}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    valid_preds = []\n",
    "    valid_labels = []\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(valid_dataloader):\n",
    "            y_pred = model(x)\n",
    "            valid_preds.append(y_pred)\n",
    "            # valid_preds.append(y_pred.detach().cpu())\n",
    "            valid_labels.append(y)\n",
    "    valid_preds = torch.cat(valid_preds)\n",
    "    valid_labels = torch.cat(valid_labels)\n",
    "    valid_loss = mae_loss_function(valid_preds, valid_labels)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), './AG_checkpoints/best_model_e5base.pth')\n",
    "        print(\"Saving a new best model\")\n",
    "    scheduler.step(best_valid_loss)\n",
    "    print(f'Epoch {epoch}, Validation Loss {valid_loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 89,
     "status": "ok",
     "timestamp": 1741719952062,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 420
    },
    "id": "WASKGkmECEMQ",
    "outputId": "08421ace-582d-4787-cba1-a92b7ad172fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized Linear(in_features=768, out_features=512, bias=True)\n",
      "initialized Linear(in_features=512, out_features=128, bias=True)\n",
      "initialized Linear(in_features=128, out_features=8, bias=True)\n",
      "initialized Linear(in_features=8, out_features=1, bias=True)\n",
      "Test Loss 0.4014216661453247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-1e405b93a024>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load('./AG_checkpoints/best_model_e5base.pth'))\n"
     ]
    }
   ],
   "source": [
    "best_model = perceptronHead2(dim_embeddings)\n",
    "best_model.to(device)\n",
    "best_model.load_state_dict(torch.load('./AG_checkpoints/best_model_e5base.pth'))\n",
    "# best_model = model\n",
    "\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_preds = []\n",
    "    test_labels = []\n",
    "    for i, (x, y) in enumerate(test_dataloader):\n",
    "        y_pred = best_model(x)\n",
    "        test_preds.append(y_pred)\n",
    "        test_labels.append(y)\n",
    "    test_preds = torch.cat(test_preds)\n",
    "    test_labels = torch.cat(test_labels)\n",
    "    test_loss = mae_loss_function(test_preds, test_labels)\n",
    "    print(f'Test Loss {test_loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1741647741175,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 420
    },
    "id": "FNd8pkfGH34B",
    "outputId": "4d4f3abd-a3fd-4831-ee92-da4175a443fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device for best_model and x: cuda\n"
     ]
    }
   ],
   "source": [
    "# prompt: # get the device best_model and x are on\n",
    "\n",
    "print(f\"Device for best_model and x: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1741647791726,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 420
    },
    "id": "bf828vtvS-te",
    "outputId": "69459d8d-2eff-4866-91f0-ee84887de5c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(next(best_model.parameters()).device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jo5l6TeUH4X5"
   },
   "source": [
    "Training with scheduler, for 200 epochs,  lr=0.01)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAeI3IVcXFmU"
   },
   "source": [
    "### TESTING BEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3117,
     "status": "ok",
     "timestamp": 1741737226638,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 420
    },
    "id": "WgPsg-omXIMB",
    "outputId": "56837da1-b2a7-4bb6-c7a7-113abfafa48f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized Linear(in_features=768, out_features=512, bias=True)\n",
      "initialized Linear(in_features=512, out_features=128, bias=True)\n",
      "initialized Linear(in_features=128, out_features=8, bias=True)\n",
      "initialized Linear(in_features=8, out_features=1, bias=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-b8631ccf4b0a>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(f'./AG_checkpoints/best_model_008_e5base.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss 0.207\n",
      "Validation Loss 0.397\n",
      "Test Loss 0.395\n"
     ]
    }
   ],
   "source": [
    "#model loading\n",
    "best_model = perceptronHead2(dim_embeddings)\n",
    "best_model.to(device)\n",
    "best_model.load_state_dict(torch.load(f'./AG_checkpoints/best_model_008_e5base.pth'))\n",
    "\n",
    "\n",
    "best_model.train()\n",
    "#train\n",
    "with torch.no_grad():\n",
    "    train_preds = []\n",
    "    train_labels = []\n",
    "    for i, (x, y) in enumerate(train_dataloader):\n",
    "        y_pred = best_model(x)\n",
    "        train_preds.append(y_pred)\n",
    "        train_labels.append(y)\n",
    "    train_preds = torch.cat(train_preds)\n",
    "    train_labels = torch.cat(train_labels)\n",
    "    train_loss = mae_loss_function(train_preds, train_labels)\n",
    "    print(f'Training Loss {round(train_loss.item(),3)}')\n",
    "\n",
    "#valid\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    valid_preds = []\n",
    "    valid_labels = []\n",
    "    for i, (x, y) in enumerate(valid_dataloader):\n",
    "        y_pred = best_model(x)\n",
    "        valid_preds.append(y_pred)\n",
    "        valid_labels.append(y)\n",
    "    valid_preds = torch.cat(valid_preds)\n",
    "    valid_labels = torch.cat(valid_labels)\n",
    "    valid_loss = mae_loss_function(valid_preds, valid_labels)\n",
    "    print(f'Validation Loss {round(valid_loss.item(),3)}')\n",
    "\n",
    "#train\n",
    "with torch.no_grad():\n",
    "    test_preds = []\n",
    "    test_labels = []\n",
    "    for i, (x, y) in enumerate(test_dataloader):\n",
    "        y_pred = best_model(x)\n",
    "        test_preds.append(y_pred)\n",
    "        test_labels.append(y)\n",
    "    test_preds = torch.cat(test_preds)\n",
    "    test_labels = torch.cat(test_labels)\n",
    "    test_loss = mae_loss_function(test_preds, test_labels)\n",
    "    print(f'Test Loss {round(test_loss.item(),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykDnQaF3Cr87"
   },
   "source": [
    "TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P1ped6-bCEIe"
   },
   "outputs": [],
   "source": [
    "best_model = myDualmodel2(dim_embeddings,dim_numerical)\n",
    "best_model.to(device)\n",
    "\n",
    "best_model.load_state_dict(torch.load('./AG_checkpoints/best_model.pth'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_preds = []\n",
    "    test_labels = []\n",
    "    for i, (x, y) in enumerate(test_dataloader):\n",
    "        y_pred = best_model(x[:,:dim_embeddings], x[:,dim_embeddings:])\n",
    "        test_preds.append(y_pred)\n",
    "        test_labels.append(y)\n",
    "    test_preds = torch.cat(test_preds)\n",
    "    test_labels = torch.cat(test_labels)\n",
    "    test_loss = mae_loss_function(test_preds, test_labels)\n",
    "    print(f'Test Loss {test_loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27232,
     "status": "ok",
     "timestamp": 1741326726326,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 480
    },
    "id": "XQMnEQhIytFV",
    "outputId": "5fa5e6fa-12f6-4d81-81b1-c7e91929f295"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Training Loss 0.3552802801132202\n",
      "Epoch 0, Validation Loss 0.35032400488853455\n",
      "Epoch 1, Training Loss 0.23885880410671234\n",
      "Epoch 1, Validation Loss 0.34637391567230225\n",
      "Epoch 2, Training Loss 0.23440074920654297\n",
      "Epoch 2, Validation Loss 0.3513180911540985\n",
      "Epoch 3, Training Loss 0.1513446867465973\n",
      "Epoch 3, Validation Loss 0.34749555587768555\n",
      "Epoch 4, Training Loss 0.19549678266048431\n",
      "Epoch 4, Validation Loss 0.3530590236186981\n",
      "Epoch 5, Training Loss 0.24011489748954773\n",
      "Epoch 5, Validation Loss 0.35078033804893494\n",
      "Epoch 6, Training Loss 0.39733004570007324\n",
      "Epoch 6, Validation Loss 0.3494114279747009\n",
      "Epoch 7, Training Loss 0.4102326035499573\n",
      "Epoch 7, Validation Loss 0.3571268916130066\n",
      "Epoch 8, Training Loss 0.2927051782608032\n",
      "Epoch 8, Validation Loss 0.3475220203399658\n",
      "Epoch 9, Training Loss 0.23760411143302917\n",
      "Epoch 9, Validation Loss 0.3474278450012207\n",
      "Epoch 10, Training Loss 0.2625439763069153\n",
      "Epoch 10, Validation Loss 0.34945937991142273\n",
      "Epoch 11, Training Loss 0.3050870895385742\n",
      "Epoch 11, Validation Loss 0.3476428687572479\n",
      "Epoch 12, Training Loss 0.3752169609069824\n",
      "Epoch 12, Validation Loss 0.34953105449676514\n",
      "Epoch 13, Training Loss 0.29223644733428955\n",
      "Epoch 13, Validation Loss 0.3480381965637207\n",
      "Epoch 14, Training Loss 0.2813258767127991\n",
      "Epoch 14, Validation Loss 0.34851160645484924\n",
      "Epoch 15, Training Loss 0.25933000445365906\n",
      "Epoch 15, Validation Loss 0.3480754792690277\n",
      "Epoch 16, Training Loss 0.2877857983112335\n",
      "Epoch 16, Validation Loss 0.3478112518787384\n",
      "Epoch 17, Training Loss 0.33500877022743225\n",
      "Epoch 17, Validation Loss 0.3475739657878876\n",
      "Epoch 18, Training Loss 0.21921253204345703\n",
      "Epoch 18, Validation Loss 0.3487531542778015\n",
      "Epoch 19, Training Loss 0.19997385144233704\n",
      "Epoch 19, Validation Loss 0.34744107723236084\n",
      "Epoch 20, Training Loss 0.33826208114624023\n",
      "Epoch 20, Validation Loss 0.3474356532096863\n",
      "Epoch 21, Training Loss 0.35898154973983765\n",
      "Epoch 21, Validation Loss 0.3472180664539337\n",
      "Epoch 22, Training Loss 0.3163658678531647\n",
      "Epoch 22, Validation Loss 0.3472532629966736\n",
      "Epoch 23, Training Loss 0.3508707284927368\n",
      "Epoch 23, Validation Loss 0.34708696603775024\n",
      "Epoch 24, Training Loss 0.37247830629348755\n",
      "Epoch 24, Validation Loss 0.3478226363658905\n"
     ]
    }
   ],
   "source": [
    "###OLD TRAINING\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00015,weight_decay=0.01)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.000015)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "epochs = 25\n",
    "my_training_loader = train_dataloader_mini\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for i, (x, y) in enumerate(my_training_loader):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x[:,:dim_embeddings], x[:,dim_embeddings:])\n",
    "        loss = mae_loss_function(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # if i % 10000 == 0:\n",
    "    train_loss /= len(my_training_loader)\n",
    "    print(f'Epoch {epoch}, Training Loss {loss.item()}')\n",
    "\n",
    "    model.eval()\n",
    "    valid_preds = []\n",
    "    valid_labels = []\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(valid_dataloader):\n",
    "            y_pred = model(x[:,:dim_embeddings], x[:,dim_embeddings:])\n",
    "            valid_preds.append(y_pred)\n",
    "            valid_labels.append(y)\n",
    "    valid_preds = torch.cat(valid_preds)\n",
    "    valid_labels = torch.cat(valid_labels)\n",
    "    valid_loss = mae_loss_function(valid_preds, valid_labels)\n",
    "    scheduler.step(valid_loss)\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), './AG_checkpoints/best_model.pth')\n",
    "        print(\"Saving a new best model\")\n",
    "    print(f'Epoch {epoch}, Validation Loss {valid_loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 329,
     "status": "ok",
     "timestamp": 1741326757701,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 480
    },
    "id": "hb6i6qWfytC8",
    "outputId": "27967c69-764b-4b67-d874-8499615e168b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-126-99bf5f4bbf31>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load('./AG_checkpoints/best_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 0.49804964661598206\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GvUCyt1Uys9e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tUlafEH0ys6o"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MIKT2FWHys4A"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3c14RQJoys1b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HrYysqgkysvJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i-nPoH4Pysgk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNlyfn/RJhYxJzKd7orDftH",
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
