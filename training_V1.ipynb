{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Credits\n",
    "Adapted from Rubungo et al. Llm-prop: Predicting physical and electronic properties of crystalline solids from their text descriptions, 2023. <br> \n",
    "Vertaix. Llm-prop: A repository for property prediction using large language models. https: //github.com/vertaix/LLM-Prop/tree/main, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2024 Vertaix\n",
    "MIT License\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13965,
     "status": "ok",
     "timestamp": 1740290793700,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 480
    },
    "id": "Y3ckIG0qI-Qa",
    "outputId": "c4cfa8e1-8fe3-4f48-a979-c7f163f38004"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 423,
     "status": "ok",
     "timestamp": 1740290794122,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 480
    },
    "id": "E-EgW_dEI-8b",
    "outputId": "a49764e9-be91-471a-c1a0-558720833254"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/cours/cs224n/project\n",
      "/content/drive/MyDrive/cours/cs224n/project/LLM-Prop\n",
      "checkpoints  LICENSE\t\t     llmprop_model.py\t  __pycache__\t    scripts\n",
      "data\t     llmprop_args_parser.py  llmprop_train.py\t  README.md\t    statistics\n",
      "embeddings   llmprop_dataset.py      llmprop_utils_OG.py  requirements.txt  stopwords\n",
      "figures      llmprop_evaluate.py     llmprop_utils.py\t  savings\t    tokenizers\n"
     ]
    }
   ],
   "source": [
    "%cd drive/MyDrive/cours/cs224n/project/\n",
    "# %cd cours/cs224n/student\n",
    "# verify that you are in the right directory\n",
    "%cd LLM-Prop/\n",
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 16596,
     "status": "ok",
     "timestamp": 1740290810719,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 480
    },
    "id": "ZDLXSxMHJS44"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "from transformers import AutoTokenizer, T5EncoderModel, T5Tokenizer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "pre_tokenizer = Whitespace()\n",
    "\n",
    "from statistics import stdev\n",
    "\n",
    "# pre-defined functions\n",
    "from llmprop_utils import *\n",
    "from llmprop_dataset import *\n",
    "from llmprop_args_parser import *\n",
    "from llmprop_train import evaluate\n",
    "from llmprop_train import train\n",
    "from llmprop_model import T5Predictor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1740290810748,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 480
    },
    "id": "gVOHsrqVXQYX",
    "outputId": "17fe0593-0e1a-4b50-8097-afcd4f6515c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available devices: 1\n",
      "Current device is: 0\n",
      "Training and testing on 1 GPUs!\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# check if the GPU is available\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'Number of available devices: {torch.cuda.device_count()}')\n",
    "    print(f'Current device is: {torch.cuda.current_device()}')\n",
    "    print(\"Training and testing on\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    print('-'*50)\n",
    "else:\n",
    "    print(\"No GPU available, please connect to the GPU first or continue to use CPU instead\")\n",
    "    print('-'*50)\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1740290810800,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 480
    },
    "id": "eC28s1LsXQV9"
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='LLM-Prop')\n",
    "parser.add_argument('--epochs',\n",
    "                    help='Number of epochs',\n",
    "                    type=int,\n",
    "                    default=200)\n",
    "parser.add_argument('--bs',\n",
    "                    help='Batch size',\n",
    "                    type=int,\n",
    "                    default=64)\n",
    "parser.add_argument('--lr',\n",
    "                    help='Learning rate',\n",
    "                    type=float,\n",
    "                    default=0.001)\n",
    "parser.add_argument('--max_len',\n",
    "                    help='Max input sequence length',\n",
    "                    type=int,\n",
    "                    default=888)\n",
    "parser.add_argument('--dr',\n",
    "                    help='Drop rate',\n",
    "                    type=float,\n",
    "                    default=0.2)\n",
    "parser.add_argument('--warmup_steps',\n",
    "                    help='Warmpup steps',\n",
    "                    type=int,\n",
    "                    default=30000)\n",
    "parser.add_argument('--preprocessing_strategy',\n",
    "                    help='Data preprocessing technique: \"none\", \"bond_lengths_replaced_with_num\", \"bond_angles_replaced_with_ang\", \"no_stopwords\", or \"no_stopwords_and_lengths_and_angles_replaced\"',\n",
    "                    type=str,\n",
    "                    default=\"no_stopwords_and_lengths_and_angles_replaced\")\n",
    "parser.add_argument('--tokenizer',\n",
    "                    help='Tokenizer name: \"t5_tokenizer\" or \"modified\"',\n",
    "                    type=str,\n",
    "                    default=\"modified\")\n",
    "parser.add_argument('--pooling',\n",
    "                    help='Pooling method. \"cls\" or \"mean\"',\n",
    "                    type=str,\n",
    "                      default=\"cls\")\n",
    "parser.add_argument('--normalizer',\n",
    "                      help='Labels scaling technique. \"z_norm\", \"mm_norm\", or \"ls_norm\"',\n",
    "                      type=str,\n",
    "                    default=\"z_norm\")\n",
    "parser.add_argument('--scheduler',\n",
    "                    help='Learning rate scheduling technique. \"linear\", \"onecycle\", \"step\", or \"lambda\" (no scheduling))',\n",
    "                    type=str,\n",
    "                    default=\"onecycle\")\n",
    "parser.add_argument('--property_name',\n",
    "                      help='The name of the property to predict. \"band_gap\", \"volume\", or \"is_gap_direct\"',\n",
    "                      type=str,\n",
    "                      default=\"band_gap\")\n",
    "parser.add_argument('--optimizer',\n",
    "                    help='Optimizer type. \"adamw\" or \"sgd\"',\n",
    "                    type=str,\n",
    "                    default=\"adamw\")\n",
    "parser.add_argument('--task_name',\n",
    "                    help='the name of the task: \"regression\" if propert_name is band_gap or volume or \"classification\" if property_name is is_gap_direct',\n",
    "                    type=str,\n",
    "                    default=\"regression\")\n",
    "parser.add_argument('--train_data_path',\n",
    "                    help=\"the path to the training data\",\n",
    "                    type=str,\n",
    "                    default=\"data/samples/textedge_prop_mp22_train.csv\")\n",
    "parser.add_argument('--valid_data_path',\n",
    "                    help=\"the path to the valid data\",\n",
    "                    type=str,\n",
    "                    default=\"data/samples/textedge_prop_mp22_valid.csv\")\n",
    "parser.add_argument('--test_data_path',\n",
    "                    help=\"the path to the test data\",\n",
    "                    type=str,\n",
    "                    default=\"data/samples/textedge_prop_mp22_test.csv\")\n",
    "parser.add_argument('--checkpoint',\n",
    "                      help=\"the path to the the best checkpoint for evaluation\",\n",
    "                      type=str,\n",
    "                      default=\"\")\n",
    "args = parser.parse_args([])\n",
    "args_dict = vars(args)\n",
    "\n",
    "# Load them into variables and use the correct variable names:\n",
    "globals().update(args_dict)\n",
    "\n",
    "# set parameters\n",
    "batch_size = bs\n",
    "max_length = max_len\n",
    "learning_rate = lr\n",
    "drop_rate = dr\n",
    "epochs = epochs\n",
    "warmup_steps = warmup_steps\n",
    "preprocessing_strategy = preprocessing_strategy\n",
    "tokenizer_name = tokenizer\n",
    "pooling = pooling\n",
    "scheduler_type = scheduler\n",
    "normalizer_type = normalizer\n",
    "property = property_name\n",
    "optimizer_type = optimizer\n",
    "task_name = task_name\n",
    "train_data_path = train_data_path\n",
    "valid_data_path = valid_data_path\n",
    "test_data_path = test_data_path\n",
    "best_model_path = checkpoint\n",
    "\n",
    "#set specific variables not default\n",
    "batch_size =32\n",
    "drop_rate = 0.4\n",
    "\n",
    "#defining datasets\n",
    "default_test_data_path =\"data/samples/textedge_prop_mp22_test.csv\"\n",
    "test_data_path = \"data/test_no_stopwords_and_lengths_and_angles_replaced.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1897,
     "status": "ok",
     "timestamp": 1740290812699,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 480
    },
    "id": "fico0GiAnnW2"
   },
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "# train_data = pd.read_csv(train_data_path)\n",
    "train_data = pd.read_csv('data/train_pp_15000.csv')\n",
    "# valid_data = pd.read_csv(valid_data_path)\n",
    "valid_data = pd.read_csv('data/val_pp_5000.csv')\n",
    "test_data = pd.read_csv(default_test_data_path)\n",
    "\n",
    "# train_data = train_data[:50]\n",
    "# valid_data = valid_data[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1740290812706,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 480
    },
    "id": "cmUV7DaSex0X",
    "outputId": "5a649c97-be12-4b6c-e65a-8d670d554269"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 7)\n",
      "(5000, 7)\n",
      "(10, 7)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(valid_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1740290812752,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 480
    },
    "id": "N7hS8qClXQTG"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# check property type to determine the task name (whether it is regression or classification)\n",
    "if train_data[property].dtype == 'bool':\n",
    "    task_name = 'classification'\n",
    "\n",
    "    #converting True->1.0 and False->0.0\n",
    "    train_data[property] = train_data[property].astype(float)\n",
    "    valid_data[property] = valid_data[property].astype(float)\n",
    "    test_data[property] = test_data[property].astype(float)\n",
    "else:\n",
    "    task_name = 'regression'\n",
    "\n",
    "train_labels_array = np.array(train_data[property])\n",
    "train_labels_mean = torch.mean(torch.tensor(train_labels_array))\n",
    "train_labels_std = torch.std(torch.tensor(train_labels_array))\n",
    "train_labels_min = torch.min(torch.tensor(train_labels_array))\n",
    "train_labels_max = torch.max(torch.tensor(train_labels_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25051,
     "status": "ok",
     "timestamp": 1740290844924,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 480
    },
    "id": "UgDGiwoJXPTj",
    "outputId": "ec0fc1b8-1a30-41e9-f4b3-af1604255260"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "train data = 15000 samples\n",
      "valid data = 5000 samples\n",
      "--------------------------------------------------\n",
      "training on 89.51333333333334% samples with whole sequence\n",
      "validating on 89.9% samples with whole sequence\n",
      "--------------------------------------------------\n",
      "labels statistics on training set:\n",
      "Mean: tensor(1.0225, dtype=torch.float64)\n",
      "Standard deviation: tensor(1.5183, dtype=torch.float64)\n",
      "Max: tensor(17.8914, dtype=torch.float64)\n",
      "Min: tensor(0., dtype=torch.float64)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# define loss functions\n",
    "mae_loss_function = nn.L1Loss()\n",
    "bce_loss_function = nn.BCEWithLogitsLoss()\n",
    "\n",
    "freeze = False # a boolean variable to determine if we freeze the pre-trained T5 weights\n",
    "\n",
    "# define the tokenizer\n",
    "if tokenizer_name == 't5_tokenizer':\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "elif tokenizer_name == 'modified':\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"tokenizers/t5_tokenizer_trained_on_modified_part_of_C4_and_textedge\")\n",
    "\n",
    "# add defined special tokens to the tokenizer\n",
    "if pooling == 'cls':\n",
    "    tokenizer.add_tokens([\"[CLS]\"])\n",
    "\n",
    "if preprocessing_strategy == \"bond_lengths_replaced_with_num\":\n",
    "    tokenizer.add_tokens([\"[NUM]\"]) # special token to replace bond lengths\n",
    "\n",
    "elif preprocessing_strategy == \"bond_angles_replaced_with_ang\":\n",
    "    tokenizer.add_tokens([\"[ANG]\"]) # special token to replace bond angles\n",
    "\n",
    "elif preprocessing_strategy == \"no_stopwords_and_lengths_and_angles_replaced\":\n",
    "    tokenizer.add_tokens([\"[NUM]\"])\n",
    "    tokenizer.add_tokens([\"[ANG]\"])\n",
    "\n",
    "print('-'*50)\n",
    "print(f\"train data = {len(train_data)} samples\")\n",
    "print(f\"valid data = {len(valid_data)} samples\")\n",
    "print('-'*50)\n",
    "print(f\"training on {get_sequence_len_stats(train_data, tokenizer, max_length)}% samples with whole sequence\")\n",
    "print(f\"validating on {get_sequence_len_stats(valid_data, tokenizer, max_length)}% samples with whole sequence\")\n",
    "print('-'*50)\n",
    "\n",
    "print(\"labels statistics on training set:\")\n",
    "print(\"Mean:\", train_labels_mean)\n",
    "print(\"Standard deviation:\", train_labels_std)\n",
    "print(\"Max:\", train_labels_max)\n",
    "print(\"Min:\", train_labels_min)\n",
    "print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203,
     "referenced_widgets": [
      "053b83fbda5e4cddae1c02f949ea7919",
      "9d497aeed43f4dafb5caf7f6fb9293e8",
      "ae9f27aa299748fcaeb8ac6d83a02ff2",
      "81e54454f2a4489b9307a6a8c415c433",
      "6945adc397bc43a599feb352006cf177",
      "b8fc82496fc74ab28d34681e6af0123e",
      "4f770ade872b401099813997659974f9",
      "4c49c1a9822f42fbaa0726004a859bf8",
      "cdafb658aa2e4d0ca1141014f016629a",
      "aa8c8b8842a24c61b064c4b7615daa90",
      "07d488eb2fd146049d8439e26e901235",
      "54e55bab20474671b908cc4b908e0a91",
      "a22219f4505145c6b1b89f4fbb04dd39",
      "e92e5c3bc5eb41cbb3df5ffd3d5c0d11",
      "661a4c2d05f041298715dae36a9ac58a",
      "645344bfedbb478e938bd72ea24a679e",
      "000beb9555f148aba0f5d038a5dafc5c",
      "f8ea7b8857d2456e94b72e30cb050f83",
      "39a5f7ad308543e98b3fdbc88a49c3da",
      "312163b0bca8492183410e45587fd066",
      "bfe73ad7e7ac4c4b93ced43e64f651e2",
      "7ad097297dca4ba3a01ef7710fb733c5"
     ]
    },
    "executionInfo": {
     "elapsed": 3573,
     "status": "ok",
     "timestamp": 1740290853014,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 480
    },
    "id": "ny0sPd3bXPQr",
    "outputId": "1e2acbf1-79b6-4396-87e7-2ed42c5bfc91"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "053b83fbda5e4cddae1c02f949ea7919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/537 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e55bab20474671b908cc4b908e0a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/308M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Embedding(32106, 512)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the model\n",
    "base_model = T5EncoderModel.from_pretrained(\"google/t5-v1_1-small\")\n",
    "base_model_output_size = 512\n",
    "\n",
    "# freeze the pre-trained LM's parameters\n",
    "if freeze:\n",
    "    for param in base_model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "# resizing the model input embeddings matrix to adapt to newly added tokens by the new tokenizer\n",
    "# this is to avoid the \"RuntimeError: CUDA error: device-side assert triggered\" error\n",
    "base_model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1740290858095,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 480
    },
    "id": "j-7mp1inecsV",
    "outputId": "f3fddefb-0e11-4fd5-b98c-891a14931123"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters = 35322049\n"
     ]
    }
   ],
   "source": [
    "    # instantiate the model\n",
    "model = T5Predictor(base_model, base_model_output_size, drop_rate=drop_rate, pooling=pooling)\n",
    "\n",
    "device_ids = [d for d in range(torch.cuda.device_count())]\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "  model = nn.DataParallel(model, device_ids=device_ids).cuda()\n",
    "else:\n",
    "  model.to(device)\n",
    "\n",
    "# print the model parameters\n",
    "model_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters = {model_trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 10918,
     "status": "ok",
     "timestamp": 1740290878637,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 480
    },
    "id": "tAJ4Nvgeecp5"
   },
   "outputs": [],
   "source": [
    "# create dataloaders\n",
    "train_dataloader = create_dataloaders(\n",
    "    tokenizer,\n",
    "    train_data,\n",
    "    max_length,\n",
    "    batch_size,\n",
    "    property_value=property,\n",
    "    pooling=pooling,\n",
    "    normalize=True,\n",
    "    normalizer=normalizer_type\n",
    ")\n",
    "\n",
    "valid_dataloader = create_dataloaders(\n",
    "    tokenizer,\n",
    "    valid_data,\n",
    "    max_length,\n",
    "    batch_size,\n",
    "    property_value=property,\n",
    "    pooling=pooling\n",
    ")\n",
    "\n",
    "test_dataloader = create_dataloaders(\n",
    "    tokenizer,\n",
    "    test_data,\n",
    "    max_length,\n",
    "    batch_size,\n",
    "    property_value=property,\n",
    "    pooling=pooling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1740290878650,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 480
    },
    "id": "IFUfMS-Xfcs4",
    "outputId": "adf62303-2818-4774-c659-687ba4a64638"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# define the optimizer\n",
    "if optimizer_type == 'adamw':\n",
    "    optimizer = AdamW(\n",
    "        model.parameters(),\n",
    "        lr = learning_rate\n",
    "    )\n",
    "elif optimizer_type == 'sgd':\n",
    "    optimizer = SGD(\n",
    "        model.parameters(),\n",
    "        lr=learn_rate\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740290878652,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 480
    },
    "id": "n6sGH1FkecnK"
   },
   "outputs": [],
   "source": [
    "# set up the scheduler\n",
    "total_training_steps = len(train_dataloader) * epochs\n",
    "if scheduler_type == 'linear':\n",
    "    scheduler = get_linear_schedule_with_warmup( #get_linear_schedule_with_warmup\n",
    "        optimizer,\n",
    "        num_warmup_steps= warmup_steps, #steps_ratio*total_training_steps,\n",
    "        num_training_steps=total_training_steps\n",
    "    )\n",
    "\n",
    "# from <https://github.com/usnistgov/alignn/blob/main/alignn/train.py>\n",
    "elif scheduler_type == 'onecycle':\n",
    "    steps_per_epoch = len(train_dataloader)\n",
    "    # pct_start = config.warmup_steps / (config.epochs * steps_per_epoch)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=learning_rate,\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        # pct_start=pct_start,\n",
    "        pct_start=0.3,\n",
    "    )\n",
    "\n",
    "elif scheduler_type == 'step':\n",
    "      # pct_start = config.warmup_steps / (config.epochs * steps_per_epoch)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "        optimizer,\n",
    "        step_size=warmup_steps\n",
    "    )\n",
    "\n",
    "elif scheduler_type == 'lambda':\n",
    "    # always return multiplier of 1 (i.e. do nothing)\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "        optimizer, lambda epoch: 1.0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1740290878659,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 480
    },
    "id": "46gOSzXmgnrO",
    "outputId": "d407abfe-37c3-4485-d10c-58c1bf1c118b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total GPU memory: 39.56 GB\n",
      "Allocated GPU memory: 0.13 GB\n",
      "Reserved GPU memory: 0.15 GB\n",
      "Free GPU memory: 39.43 GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((15000, 7), (5000, 7), (10, 7))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get GPU memory information\n",
    "total_memory = torch.cuda.get_device_properties(device).total_memory\n",
    "allocated_memory = torch.cuda.memory_allocated(device)\n",
    "reserved_memory = torch.cuda.memory_reserved(device)\n",
    "free_memory = total_memory - allocated_memory\n",
    "\n",
    "print(f\"Total GPU memory: {total_memory / (1024**3):.2f} GB\")\n",
    "print(f\"Allocated GPU memory: {allocated_memory / (1024**3):.2f} GB\")\n",
    "print(f\"Reserved GPU memory: {reserved_memory / (1024**3):.2f} GB\")\n",
    "print(f\"Free GPU memory: {free_memory / (1024**3):.2f} GB\")\n",
    "\n",
    "train_data.shape, valid_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740290878672,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 480
    },
    "id": "qnNh0YNhjk23"
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    model,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    bce_loss_function,\n",
    "    mae_loss_function,\n",
    "    epochs,\n",
    "    train_dataloader,\n",
    "    valid_dataloader,\n",
    "    device,\n",
    "    normalizer=\"z_norm\",\n",
    "    task_name=\"regression\"\n",
    "):\n",
    "\n",
    "    training_starting_time = time.time()\n",
    "    training_stats = []\n",
    "    validation_predictions = {}\n",
    "\n",
    "    best_loss = 1e10 # Set the best loss variable which record the best loss for each epoch\n",
    "    best_roc = 0.0\n",
    "    print(task_name)\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"========== Epoch {epoch+1}/{epochs} =========\")\n",
    "\n",
    "        epoch_starting_time = time.time()\n",
    "\n",
    "        total_training_loss = 0\n",
    "        total_training_mae_loss = 0\n",
    "        total_training_normalized_mae_loss = 0\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for step, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "\n",
    "            print(f\"Step {step+1}/{len(train_dataloader)}\")\n",
    "\n",
    "            batch_inputs, batch_masks, batch_labels, batch_norm_labels = tuple(b.to(device) for b in batch)\n",
    "\n",
    "            _, predictions = model(batch_inputs, batch_masks)\n",
    "\n",
    "            if task_name == 'classification':\n",
    "                loss = bce_loss_function(predictions.squeeze(), batch_labels.squeeze())\n",
    "\n",
    "            elif task_name == 'regression':\n",
    "                loss = mae_loss_function(predictions.squeeze(), batch_norm_labels.squeeze())\n",
    "\n",
    "                if normalizer == 'z_norm':\n",
    "                    predictions_denorm = z_denormalize(predictions, train_labels_mean, train_labels_std)\n",
    "\n",
    "                elif normalizer == 'mm_norm':\n",
    "                    predictions_denorm = mm_denormalize(predictions, train_labels_min, train_labels_max)\n",
    "\n",
    "                elif normalizer == 'ls_norm':\n",
    "                    predictions_denorm = ls_denormalize(predictions)\n",
    "\n",
    "                elif normalizer == 'no_norm':\n",
    "                    loss = mae_loss_function(predictions.squeeze(), batch_labels.squeeze())\n",
    "                    predictions_denorm = predictions\n",
    "\n",
    "                mae_loss = mae_loss_function(predictions_denorm.squeeze(), batch_labels.squeeze())\n",
    "\n",
    "            # total training loss on actual output\n",
    "            if task_name == \"classification\":\n",
    "                total_training_loss += loss.item()\n",
    "\n",
    "            elif task_name == \"regression\":\n",
    "                total_training_loss += mae_loss.item()\n",
    "\n",
    "            # back propagate\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # average training loss on actual output\n",
    "        average_training_loss = total_training_loss/len(train_dataloader)\n",
    "\n",
    "        epoch_ending_time = time.time()\n",
    "        training_time = time_format(epoch_ending_time - epoch_starting_time)\n",
    "\n",
    "        print(f\"Average training loss = {average_training_loss}\")\n",
    "        print(f\"Training for this epoch took {training_time}\")\n",
    "\n",
    "        # Validation\n",
    "        print(\"\")\n",
    "        print(\"Running Validation ....\")\n",
    "\n",
    "        valid_start_time = time.time()\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        total_eval_mae_loss = 0\n",
    "        predictions_list = []\n",
    "        targets_list = []\n",
    "\n",
    "        for step, batch in tqdm(enumerate(valid_dataloader), total=len(valid_dataloader)):\n",
    "            batch_inputs, batch_masks, batch_labels = tuple(b.to(device) for b in batch)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                _, predictions = model(batch_inputs, batch_masks)\n",
    "\n",
    "                if task_name == \"classification\":\n",
    "                    predictions_denorm = predictions\n",
    "\n",
    "                elif task_name == \"regression\":\n",
    "                    if normalizer == 'z_norm':\n",
    "                        predictions_denorm = z_denormalize(predictions, train_labels_mean, train_labels_std)\n",
    "\n",
    "                    elif normalizer == 'mm_norm':\n",
    "                        predictions_denorm = mm_denormalize(predictions, train_labels_min, train_labels_max)\n",
    "\n",
    "                    elif normalizer == 'ls_norm':\n",
    "                        predictions_denorm = ls_denormalize(predictions)\n",
    "\n",
    "                    elif normalizer == 'no_norm':\n",
    "                        predictions_denorm = predictions\n",
    "\n",
    "            predictions = predictions_denorm.detach().cpu().numpy()\n",
    "            targets = batch_labels.detach().cpu().numpy()\n",
    "\n",
    "            for i in range(len(predictions)):\n",
    "                predictions_list.append(predictions[i][0])\n",
    "                targets_list.append(targets[i])\n",
    "\n",
    "        valid_ending_time = time.time()\n",
    "        validation_time = time_format(valid_ending_time-valid_start_time)\n",
    "\n",
    "        # save model checkpoint and the statistics of the epoch where the model performs the best\n",
    "        if task_name == \"classification\":\n",
    "            valid_performance = get_roc_score(predictions_list, targets_list)\n",
    "\n",
    "            if valid_performance >= best_roc:\n",
    "                best_roc = valid_performance\n",
    "                best_epoch = epoch+1\n",
    "\n",
    "                # save the best model checkpoint\n",
    "                save_to_path = f\"checkpoints/samples/{task_name}/best_checkpoint_for_{property}.pt\"\n",
    "                if isinstance(model, nn.DataParallel):\n",
    "                    torch.save(model.module.state_dict(), save_to_path)\n",
    "                    compressCheckpointsWithTar(save_to_path)\n",
    "                else:\n",
    "                    torch.save(model.state_dict(), save_to_path)\n",
    "                    compressCheckpointsWithTar(save_to_path)\n",
    "\n",
    "                # save statistics of the best model\n",
    "                training_stats.append(\n",
    "                    {\n",
    "                        \"best_epoch\": epoch + 1,\n",
    "                        \"training_loss\": average_training_loss,\n",
    "                        \"validation_roc_score\": valid_performance,\n",
    "                        \"training time\": training_time,\n",
    "                        \"validation time\": validation_time\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                validation_predictions.update(\n",
    "                    {\n",
    "                        f\"epoch_{epoch+1}\": predictions_list\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                saveCSV(pd.DataFrame(data=training_stats), f\"statistics/samples/{task_name}/training_stats_for_{property}.csv\")\n",
    "                saveCSV(pd.DataFrame(validation_predictions), f\"statistics/samples/{task_name}/validation_stats_for_{property}.csv\")\n",
    "\n",
    "            else:\n",
    "                best_roc = best_roc\n",
    "\n",
    "            print(f\"Validation roc score = {valid_performance}\")\n",
    "\n",
    "        elif task_name == \"regression\":\n",
    "            predictions_tensor = torch.tensor(predictions_list)\n",
    "            targets_tensor = torch.tensor(targets_list)\n",
    "            valid_performance = mae_loss_function(predictions_tensor.squeeze(), targets_tensor.squeeze())\n",
    "\n",
    "            if valid_performance <= best_loss:\n",
    "                best_loss = valid_performance\n",
    "                best_epoch = epoch+1\n",
    "\n",
    "                # save the best model checkpoint\n",
    "                save_to_path = f\"checkpoints/samples/{task_name}/best_checkpoint_for_{property}.pt\"\n",
    "                if isinstance(model, nn.DataParallel):\n",
    "                    torch.save(model.module.state_dict(), save_to_path)\n",
    "                    compressCheckpointsWithTar(save_to_path)\n",
    "                else:\n",
    "                    torch.save(model.state_dict(), save_to_path)\n",
    "                    compressCheckpointsWithTar(save_to_path)\n",
    "\n",
    "                # save statistics of the best model\n",
    "                training_stats.append(\n",
    "                    {\n",
    "                        \"best_epoch\": epoch + 1,\n",
    "                        \"training mae loss\": average_training_loss,\n",
    "                        \"validation mae loss\": valid_performance,\n",
    "                        \"training time\": training_time,\n",
    "                        \"validation time\": validation_time\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                validation_predictions.update(\n",
    "                    {\n",
    "                        f\"epoch_{epoch+1}\": predictions_list\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                saveCSV(pd.DataFrame(data=training_stats), f\"statistics/samples/{task_name}/training_stats_for_{property}.csv\")\n",
    "                saveCSV(pd.DataFrame(validation_predictions), f\"statistics/samples/{task_name}/validation_stats_for_{property}.csv\")\n",
    "\n",
    "            else:\n",
    "                best_loss = best_loss\n",
    "\n",
    "            print(f\"Validation mae error = {valid_performance}\")\n",
    "        print(f\"validation took {validation_time}\")\n",
    "    train_ending_time = time.time()\n",
    "    total_training_time = train_ending_time-training_starting_time\n",
    "\n",
    "    print(\"\\n========== Training complete ========\")\n",
    "    print(f\"Training LLM_Prop on {property} prediction took {time_format(total_training_time)}\")\n",
    "\n",
    "    if task_name == \"classification\":\n",
    "        print(f\"The lowest roc score achieved on validation set on {property} is {best_roc} at {best_epoch}th epoch \\n\")\n",
    "\n",
    "    elif task_name == \"regression\":\n",
    "        print(f\"The lowest mae error achieved on validation set on predicting {property} is {best_loss} at {best_epoch}th epoch \\n\")\n",
    "\n",
    "    return training_stats, validation_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1740290975748,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 480
    },
    "id": "uoIJ5slKfDyk",
    "outputId": "0dddc4e5-b054-42e4-90f0-578bc16263e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 0.4, (15000, 7), (5000, 7))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size,drop_rate,train_data.shape,valid_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "output_embedded_package_id": "1U_Lm4kFOM1qBgqv9_-h2l8qFhyBrCr9t"
    },
    "executionInfo": {
     "elapsed": 72545822,
     "status": "ok",
     "timestamp": 1740363524882,
     "user": {
      "displayName": "Alexis Geslin",
      "userId": "05368027719046732967"
     },
     "user_tz": 480
    },
    "id": "7ODEbt_qgMV7",
    "outputId": "d337ffe3-05af-47a5-e524-ba67fd5f555f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"======= Training ... ========\")\n",
    "training_stats, validation_predictions = train(model, optimizer, scheduler, mae_loss_function, mae_loss_function,\n",
    "    epochs, train_dataloader, valid_dataloader, device, normalizer=normalizer_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6BBu6lQ0iJdr"
   },
   "outputs": [],
   "source": [
    "for _ in range(3):  # Sometimes needs multiple passes\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()\n",
    "del model\n",
    "torch.cuda.reset_max_memory_allocated()  # Frees unused memory\n",
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "og8puwkygMMU"
   },
   "outputs": [],
   "source": [
    "torch.cuda.memory_allocated()/1024/1024/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "opjH4vTuo1gs"
   },
   "outputs": [],
   "source": [
    "model.to_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oh0DkCwZo1at"
   },
   "outputs": [],
   "source": [
    "# prompt: move model to cpu\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0vv-H-eBJwgF"
   },
   "outputs": [],
   "source": [
    "# ! bash scripts/llmprop_train.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I2WLtx95KARC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNFyhVczOFpjSjjYtk8li0W",
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "000beb9555f148aba0f5d038a5dafc5c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "053b83fbda5e4cddae1c02f949ea7919": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9d497aeed43f4dafb5caf7f6fb9293e8",
       "IPY_MODEL_ae9f27aa299748fcaeb8ac6d83a02ff2",
       "IPY_MODEL_81e54454f2a4489b9307a6a8c415c433"
      ],
      "layout": "IPY_MODEL_6945adc397bc43a599feb352006cf177"
     }
    },
    "07d488eb2fd146049d8439e26e901235": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "312163b0bca8492183410e45587fd066": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "39a5f7ad308543e98b3fdbc88a49c3da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c49c1a9822f42fbaa0726004a859bf8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f770ade872b401099813997659974f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "54e55bab20474671b908cc4b908e0a91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a22219f4505145c6b1b89f4fbb04dd39",
       "IPY_MODEL_e92e5c3bc5eb41cbb3df5ffd3d5c0d11",
       "IPY_MODEL_661a4c2d05f041298715dae36a9ac58a"
      ],
      "layout": "IPY_MODEL_645344bfedbb478e938bd72ea24a679e"
     }
    },
    "645344bfedbb478e938bd72ea24a679e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "661a4c2d05f041298715dae36a9ac58a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bfe73ad7e7ac4c4b93ced43e64f651e2",
      "placeholder": "",
      "style": "IPY_MODEL_7ad097297dca4ba3a01ef7710fb733c5",
      "value": "308M/308M[00:02&lt;00:00,157MB/s]"
     }
    },
    "6945adc397bc43a599feb352006cf177": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ad097297dca4ba3a01ef7710fb733c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "81e54454f2a4489b9307a6a8c415c433": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa8c8b8842a24c61b064c4b7615daa90",
      "placeholder": "",
      "style": "IPY_MODEL_07d488eb2fd146049d8439e26e901235",
      "value": "537/537[00:00&lt;00:00,59.5kB/s]"
     }
    },
    "9d497aeed43f4dafb5caf7f6fb9293e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b8fc82496fc74ab28d34681e6af0123e",
      "placeholder": "",
      "style": "IPY_MODEL_4f770ade872b401099813997659974f9",
      "value": "config.json:100%"
     }
    },
    "a22219f4505145c6b1b89f4fbb04dd39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_000beb9555f148aba0f5d038a5dafc5c",
      "placeholder": "",
      "style": "IPY_MODEL_f8ea7b8857d2456e94b72e30cb050f83",
      "value": "pytorch_model.bin:100%"
     }
    },
    "aa8c8b8842a24c61b064c4b7615daa90": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae9f27aa299748fcaeb8ac6d83a02ff2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c49c1a9822f42fbaa0726004a859bf8",
      "max": 537,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cdafb658aa2e4d0ca1141014f016629a",
      "value": 537
     }
    },
    "b8fc82496fc74ab28d34681e6af0123e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bfe73ad7e7ac4c4b93ced43e64f651e2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cdafb658aa2e4d0ca1141014f016629a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e92e5c3bc5eb41cbb3df5ffd3d5c0d11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39a5f7ad308543e98b3fdbc88a49c3da",
      "max": 307932125,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_312163b0bca8492183410e45587fd066",
      "value": 307932125
     }
    },
    "f8ea7b8857d2456e94b72e30cb050f83": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
